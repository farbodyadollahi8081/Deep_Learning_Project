{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95whQ5xs42-y",
    "outputId": "4b4d5d20-4653-4b77-f779-93d3ff50d168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
      "Collecting gdown\n",
      "  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Installing collected packages: gdown\n",
      "  Attempting uninstall: gdown\n",
      "    Found existing installation: gdown 4.4.0\n",
      "    Uninstalling gdown-4.4.0:\n",
      "      Successfully uninstalled gdown-4.4.0\n",
      "Successfully installed gdown-4.6.0\n"
     ]
    }
   ],
   "source": [
    "pip install -U --no-cache-dir gdown --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rM4oa5KezakY"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import numpy as np\n",
    "import gdown\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import ToTensor,Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import re\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from google.colab.patches import cv2_imshow\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data & Preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4j689z9SzsBh",
    "outputId": "c0f6228d-15e3-49a9-f1a7-65b3def56bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vJAeogtTzxbJ"
   },
   "outputs": [],
   "source": [
    "def donwload_to_file(grdive_path,file_name,output_path):\n",
    "  \"\"\"\n",
    "  function for downloading zip files from google drive and save it to desired path on colab\n",
    "\n",
    "  inputs:\n",
    "    grdive_path: path of file we want to download (url should be in export=download format)\n",
    "    file_name: name of file we want to download\n",
    "    output_path:path we extract data into\n",
    "  outputs:\n",
    "    we dont have any output!\n",
    "\n",
    "  \"\"\"\n",
    "  gdown.download(grdive_path, file_name)\n",
    "  with ZipFile(file_name, 'r') as zipObj:\n",
    "   # Extract all the contents of zip file in current directory\n",
    "   zipObj.extractall(output_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aqz8nzBxz3to",
    "outputId": "87901946-f0d4-4459-feec-278b0128927b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/u/0/uc?id=1GAZgPpTUBSfhne-Tp0GDkvSHuq6EMMbj&export=download\n",
      "To: /content/train_ende.zip\n",
      "100%|██████████| 2.90G/2.90G [00:17<00:00, 165MB/s]\n"
     ]
    }
   ],
   "source": [
    "# for train\n",
    "donwload_to_file('https://drive.google.com/u/0/uc?id=1GAZgPpTUBSfhne-Tp0GDkvSHuq6EMMbj&export=download','train_ende.zip','/content/gdrive/MyDrive/Phase_0_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BwtnD5tM12A"
   },
   "outputs": [],
   "source": [
    "# renaming train folder name (it's train_ende) to just train so it is more consistent with other folders names\n",
    "os.rename('/content/gdrive/MyDrive/Phase_0_images/train_ende','/content/gdrive/MyDrive/Phase_0_images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wgk_4c1I5ZHs",
    "outputId": "80869b7e-46bd-45db-ff47-730ef9c67cbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/u/0/uc?id=12HM8uVNjFg-HRZ15ADue4oLGFAYQwvTA&export=download\n",
      "To: /content/dev.zip\n",
      "100%|██████████| 638M/638M [00:12<00:00, 51.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# for validation\n",
    "donwload_to_file('https://drive.google.com/u/0/uc?id=12HM8uVNjFg-HRZ15ADue4oLGFAYQwvTA&export=download','dev.zip','/content/gdrive/MyDrive/Phase_0_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uThFNCB_5ahj",
    "outputId": "5634ec7d-d17e-4422-a16e-efc69de0b7b4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/u/0/uc?id=1B9ZFmSTqfTMaqJ15nQDrRNLqBvo-B39W&export=download\n",
      "To: /content/test.zip\n",
      "100%|██████████| 641M/641M [00:08<00:00, 73.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "# for test\n",
    "donwload_to_file('https://drive.google.com/u/0/uc?id=1B9ZFmSTqfTMaqJ15nQDrRNLqBvo-B39W&export=download','test.zip','/content/gdrive/MyDrive/Phase_0_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKxW1AJS_vlZ",
    "outputId": "b7405402-22f2-4938-fb52-b9407ed14de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'MSCTD'...\n",
      "remote: Enumerating objects: 1217, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
      "remote: Total 1217 (delta 13), reused 7 (delta 3), pack-reused 1190\u001b[K\n",
      "Receiving objects: 100% (1217/1217), 102.24 MiB | 25.68 MiB/s, done.\n",
      "Resolving deltas: 100% (616/616), done.\n",
      "Checking out files: 100% (934/934), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/XL2248/MSCTD.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ndgt42En5b9u"
   },
   "outputs": [],
   "source": [
    "class MSTCDDate(Dataset):\n",
    "   \n",
    "\n",
    "  def __init__(self,image_path,txt_path,language,mode,image_format,scale, transform=None, target_transform=None):\n",
    "     \n",
    "      text_loader = language + '_' + mode + '.txt'\n",
    "      sentiment_loader = 'sentiment_' + mode+'.txt'\n",
    "      index_file = 'image_index_' + mode + '.txt'\n",
    "      self.image_path = image_path\n",
    "      self.transform = transform\n",
    "      self.target_transform = target_transform\n",
    "      self.mode = mode\n",
    "      self.image_format = image_format\n",
    "      self.scale = scale\n",
    "      for file_names in os.scandir(txt_path):\n",
    "        name_file = os.path.basename(file_names)\n",
    "        if name_file == text_loader:\n",
    "          with open(file_names.path) as f:\n",
    "            self.text_file = [line.rstrip('\\n') for line in f]\n",
    "        if name_file == sentiment_loader:\n",
    "          with open(file_names.path) as f:\n",
    "            self.sentiment_file = [line.rstrip('\\n') for line in f]\n",
    "        if name_file == index_file:\n",
    "          with open(file_names.path) as f:\n",
    "            self.index_file = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.text_file)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      image_path_complete = self.image_path + '/' + self.mode + '/'\n",
    "      text_file_chosen = self.text_file[idx]\n",
    "      sentiment_chosen = int(self.sentiment_file[idx])\n",
    "      temp_image = cv2.imread(image_path_complete+str(idx)+ '.' + self.image_format)\n",
    "      n1,n2,n3 = np.shape(temp_image)\n",
    "      if self.scale != 1:\n",
    "        image = resize(temp_image,[int(n1/self.scale),int(n2/self.scale)], anti_aliasing=True)\n",
    "      else:\n",
    "        image = temp_image\n",
    "      if self.transform:\n",
    "          image = self.transform(image)\n",
    "      if self.target_transform:\n",
    "          label = self.target_transform(sentiment_chosen)\n",
    "      return  text_file_chosen,sentiment_chosen,image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "btU0oKnR5lLa"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transformation= transforms.Compose([transforms.ToTensor(),transforms.Resize((50,100)),transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EBqLcHcw5lNt"
   },
   "outputs": [],
   "source": [
    "train_dataset= MSTCDDate('/content/gdrive/MyDrive/Phase_0_images' ,'/content/MSCTD/MSCTD_data/ende','english','train','jpg',1,  transform = transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tx1slDjIl3CI"
   },
   "outputs": [],
   "source": [
    "test_dataset= MSTCDDate('/content/gdrive/MyDrive/Phase_0_images' ,'/content/MSCTD/MSCTD_data/ende','english','test','jpg',1,  transform = transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bijtXqWil_EI"
   },
   "outputs": [],
   "source": [
    "val_dataset= MSTCDDate('/content/gdrive/MyDrive/Phase_0_images' ,'/content/MSCTD/MSCTD_data/ende','english','dev','jpg',1,  transform = transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dejROF8cSwQ2"
   },
   "outputs": [],
   "source": [
    "dataset_sizes = {'train':len(train_dataset),'test':len(test_dataset),'val':len(val_dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HlVwoG-YVIkS"
   },
   "outputs": [],
   "source": [
    "#creating a list of Train data for faster loading\n",
    "train_data_set=[]\n",
    "for a in train_dataset:\n",
    "  train_data_set.append([a[2],a[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUk269Tx8PlG"
   },
   "outputs": [],
   "source": [
    "#creating a list of Test data for faster loading\n",
    "test_data_set=[]\n",
    "for a in test_dataset:\n",
    "  test_data_set.append([a[2],a[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6MV2HVnN8Pni"
   },
   "outputs": [],
   "source": [
    "#creating a list of Val data for faster loading\n",
    "val_data_set=[]\n",
    "for a in val_dataset:\n",
    "  val_data_set.append([a[2],a[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ye7mJ1fX5lP_"
   },
   "outputs": [],
   "source": [
    "#Creating Batch\n",
    "from torch.utils.data import DataLoader\n",
    "train_data_loader= DataLoader(train_data_set,batch_size=64,shuffle = True)\n",
    "test_data_loader= DataLoader(test_data_set,batch_size=64,shuffle = True)\n",
    "val_data_loader= DataLoader(val_data_set,batch_size=64,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQwjF38XDpov",
    "outputId": "b2bacbb5-1cb0-4dfc-e6c5-57a784f1aec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "779e07917c1f44b2a2e03db504a03f30",
      "e257b6ff1e784a06b18ce692528c1d53",
      "5fb270b6326e44c8b3abcad0d54a8c24",
      "7a9448d42f144833bbac274cd03d8e84",
      "6a879a6321264270bbf729f1bddb7b4e",
      "9ff23592487240ab87f8ad45255727ea",
      "a6e6559ea13843f7ba43c61a4257c347",
      "bb52696ddf264cacbc582af0bd4cacf2",
      "fdf4610c67d44f0d93bd41939000b3e1",
      "bbcfc085748943a5bcf204fe39f7e862",
      "c8291d0bf13249719bd354e3fb14a971"
     ]
    },
    "id": "pQAztZ1OCTmG",
    "outputId": "df1ad477-3682-4126-9d89-50015592af84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779e07917c1f44b2a2e03db504a03f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Loading pre Trained Resnet50\n",
    "model_resnet = torchvision.models.resnet50(pretrained=True)\n",
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(num_ftrs, 3) # we have 3 output class\n",
    "\n",
    "model_resnet = model_resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "G6RPCa2zMk6y"
   },
   "outputs": [],
   "source": [
    "#Loading pre Trained mobilenet_v3\n",
    "model_mobilenetv3 = torchvision.models.mobilenet_v3_large(pretrained=True)\n",
    "for param in model_mobilenetv3.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "model_mobilenetv3.classifier[3] = nn.Linear(1280, 3) # we have 3 output class\n",
    "\n",
    "model_mobilenetv3 = model_mobilenetv3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "mwSxEouSMmI5"
   },
   "outputs": [],
   "source": [
    "#Loading pre Trained VGG16\n",
    "model_vgg = torchvision.models.vgg16(pretrained=True)\n",
    "for param in model_vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "model_vgg.classifier[6] = nn.Linear(4096, 3) # we have 3 output class\n",
    "model_vgg = model_vgg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "j44B6A4dDuIp"
   },
   "outputs": [],
   "source": [
    "def train_model_manual(model, criterion, optimizer,scheduler,val_beark, num_epochs=25):\n",
    "  \"\"\"\n",
    "  function for train our model! in this function we use dataloader directly. so we only can use it for our CIFAR10 dataset with our input name.\n",
    "  inputs: \n",
    "      model: input model \n",
    "      criterion: desired loss function\n",
    "      optimizer: our optimizer(!)\n",
    "      scheduler: for changing learning rate after sum epochs\n",
    "      num_epochs: number of epoches\n",
    "      val_beark: threshold for early stopping, if after \"val_beark\" steps our model don't get better, we end procces\n",
    "  output:\n",
    "      model: our trained model!\n",
    "\n",
    "\n",
    "  \"\"\"\n",
    "  train_acc = []\n",
    "  train_loss = []\n",
    "  test_acc = []\n",
    "  test_loss = []\n",
    "  since = time.time()\n",
    "\n",
    "  best_model_wts = copy.deepcopy(model.state_dict())\n",
    "  best_acc = 0.0\n",
    "  best_loss = 100000000000\n",
    "  counter_val_beark = 0\n",
    "  for epoch in range(num_epochs):\n",
    "    ### Training\n",
    "    model.train()\n",
    "    loss_train = 0\n",
    "    acc_train = 0\n",
    "    counter = 1\n",
    "    for TK in train_data_loader:\n",
    "      # 1. Forward pass\n",
    "      batch = TK[0]\n",
    "      label = TK[1]\n",
    "      batch = batch.to(device)\n",
    "      label = label.to(device)\n",
    "      outputs = model(batch) # model outputs raw logits \n",
    "      _, preds = torch.max(outputs, 1)\n",
    "\n",
    "      # print(y_logits)\n",
    "      # 2. Calculate loss and accuracy\n",
    "      counter = counter + 1\n",
    "      loss = criterion(outputs, label)\n",
    "      acc_train += torch.sum(preds == label.data)\n",
    "      loss_train = loss_train + loss\n",
    "      # 3. Optimizer zero grad\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 4. Loss backwards\n",
    "      loss.backward()\n",
    "\n",
    "      # 5. Optimizer step\n",
    "      optimizer.step()\n",
    "    loss_train = loss_train/counter\n",
    "    acc_train = acc_train/dataset_sizes['train']\n",
    "    train_acc.append(acc_train)\n",
    "    train_loss.append(loss_train)\n",
    "    scheduler.step()\n",
    "    ### Testing\n",
    "    loss_test = 0\n",
    "    acc_test = 0\n",
    "    counter = 1\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      for TK in val_data_loader:\n",
    "      # 1. Forward pass\n",
    "        batch = TK[0]\n",
    "        label = TK[1]\n",
    "        batch = batch.to(device)\n",
    "        label = label.to(device)\n",
    "        output = model(batch) # model outputs raw logits \n",
    "        _, preds = torch.max(output, 1)\n",
    "        loss_test= criterion(output, label.data)\n",
    "        acc_test += torch.sum(preds == label.data)\n",
    "      loss_test = loss_test/counter\n",
    "      acc_test = acc_test/dataset_sizes['val']\n",
    "      test_loss.append(loss_test)\n",
    "      test_acc.append(acc_test)\n",
    "    if acc_test > best_acc:\n",
    "                best_acc = acc_test\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    if loss_test <= best_loss:\n",
    "                best_loss = loss_test\n",
    "                counter_val_beark = 0\n",
    "    if loss_test > best_loss:\n",
    "                counter_val_beark = counter_val_beark + 1\n",
    "                if (counter_val_beark > val_beark):\n",
    "                  print(f\"early stopping happend!\")\n",
    "                  break;\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 1 == 0:\n",
    "      print(f\"Epoch: {epoch} | Loss: {loss_train:.5f}, Acc: {acc_train:.2f}% | Test Loss: {loss_test:.5f}, Test Acc: {acc_test:.2f}%\") \n",
    "  time_elapsed = time.time() - since\n",
    "  print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "  print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "  # load best model weights\n",
    "  model.load_state_dict(best_model_wts)\n",
    "  return model,best_loss,best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tunning Pre Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "psxUikmQDuK3",
    "outputId": "1128f63d-8ad5-4244-f8f6-7fd99a098c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.09783, Acc: 0.39% | Test Loss: 1.21394, Test Acc: 0.32%\n",
      "Epoch: 1 | Loss: 1.08603, Acc: 0.40% | Test Loss: 1.14618, Test Acc: 0.35%\n",
      "Epoch: 2 | Loss: 1.07884, Acc: 0.41% | Test Loss: 1.18054, Test Acc: 0.36%\n",
      "Epoch: 3 | Loss: 1.07899, Acc: 0.41% | Test Loss: 1.24866, Test Acc: 0.36%\n",
      "Epoch: 4 | Loss: 1.07519, Acc: 0.42% | Test Loss: 1.00446, Test Acc: 0.36%\n",
      "Training complete in 0m 53s\n",
      "Best val Acc: 0.363223\n"
     ]
    }
   ],
   "source": [
    "#Fine Tunning Resnet50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer_conv = optim.SGD(model_resnet.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=50, gamma=0.5)\n",
    "\n",
    "model_resnet = model_resnet.to(device)\n",
    "model_resnet_trained,best_loss,best_acc = train_model_manual(model_part_2, criterion, optimizer_conv,exp_lr_scheduler,20,\n",
    "                         num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrDlIW7f5lSM",
    "outputId": "cb2fea2d-a300-4505-8e39-7bb6407315c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.14643, Acc: 0.36% | Test Loss: 1.10467, Test Acc: 0.36%\n",
      "Epoch: 1 | Loss: 1.10701, Acc: 0.39% | Test Loss: 1.07378, Test Acc: 0.35%\n",
      "Epoch: 2 | Loss: 1.10185, Acc: 0.40% | Test Loss: 1.07485, Test Acc: 0.36%\n",
      "Epoch: 3 | Loss: 1.10101, Acc: 0.40% | Test Loss: 1.10958, Test Acc: 0.36%\n",
      "Epoch: 4 | Loss: 1.09823, Acc: 0.40% | Test Loss: 1.03149, Test Acc: 0.36%\n",
      "Training complete in 0m 24s\n",
      "Best val Acc: 0.364408\n"
     ]
    }
   ],
   "source": [
    "#Fine Tunning mobilenetv3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer_conv = optim.SGD(model_mobilenetv3.classifier[3].parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=50, gamma=0.5)\n",
    "\n",
    "model_mobilenetv3 = model_mobilenetv3.to(device)\n",
    "model_mobilenetv3_trained,best_loss,best_acc = train_model_manual(model_mobilenetv3, criterion, optimizer_conv,exp_lr_scheduler,20,\n",
    "                         num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOlyv1QBK6lF",
    "outputId": "3076865f-3250-4487-803e-fa12beb4bb3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.31329, Acc: 0.36% | Test Loss: 1.17500, Test Acc: 0.33%\n",
      "Epoch: 1 | Loss: 1.31745, Acc: 0.37% | Test Loss: 1.00009, Test Acc: 0.35%\n",
      "Epoch: 2 | Loss: 1.32392, Acc: 0.37% | Test Loss: 0.79377, Test Acc: 0.37%\n",
      "Epoch: 3 | Loss: 1.31586, Acc: 0.38% | Test Loss: 1.17152, Test Acc: 0.34%\n",
      "Epoch: 4 | Loss: 1.31931, Acc: 0.37% | Test Loss: 1.20625, Test Acc: 0.37%\n",
      "Training complete in 1m 31s\n",
      "Best val Acc: 0.367569\n"
     ]
    }
   ],
   "source": [
    "#Fine Tunning vgg16\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer_conv = optim.SGD(model_vgg.classifier[6].parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=50, gamma=0.5)\n",
    "\n",
    "model_vgg = model_vgg.to(device)\n",
    "model_vgg_trained,best_loss,best_acc = train_model_manual(model_vgg, criterion, optimizer_conv,exp_lr_scheduler,20,\n",
    "                         num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0HDgYAscwVP"
   },
   "source": [
    "Based on robustness of results, we choose VGG16 for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MLZUFhSc8TJ",
    "outputId": "7affb7a8-3cea-4174-c31a-81c289629119"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Loading pre Trained VGG16 Again!\n",
    "\n",
    "model_vgg = torchvision.models.vgg16(pretrained=True)\n",
    "for param in model_vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "model_vgg.classifier[6] = nn.Linear(4096, 3) # we have 3 output class\n",
    "model_vgg = model_vgg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjNjLLW1cvDr",
    "outputId": "bbf30d16-ff2f-4f8a-86ca-858c39e7b37e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.32638, Acc: 0.35% | Test Loss: 0.90314, Test Acc: 0.37%\n",
      "Epoch: 1 | Loss: 1.31605, Acc: 0.37% | Test Loss: 1.15904, Test Acc: 0.37%\n",
      "Epoch: 2 | Loss: 1.30484, Acc: 0.37% | Test Loss: 0.86959, Test Acc: 0.37%\n",
      "Epoch: 3 | Loss: 1.32128, Acc: 0.37% | Test Loss: 1.14432, Test Acc: 0.35%\n",
      "Epoch: 4 | Loss: 1.31786, Acc: 0.37% | Test Loss: 1.15239, Test Acc: 0.33%\n",
      "Epoch: 5 | Loss: 1.32229, Acc: 0.38% | Test Loss: 0.92662, Test Acc: 0.36%\n",
      "Epoch: 6 | Loss: 1.31652, Acc: 0.38% | Test Loss: 1.29277, Test Acc: 0.33%\n",
      "Epoch: 7 | Loss: 1.31066, Acc: 0.38% | Test Loss: 1.25141, Test Acc: 0.37%\n",
      "Epoch: 8 | Loss: 1.31859, Acc: 0.37% | Test Loss: 1.29200, Test Acc: 0.37%\n",
      "Epoch: 9 | Loss: 1.32126, Acc: 0.37% | Test Loss: 1.07426, Test Acc: 0.36%\n",
      "Epoch: 10 | Loss: 1.32192, Acc: 0.38% | Test Loss: 1.25647, Test Acc: 0.34%\n",
      "Epoch: 11 | Loss: 1.31920, Acc: 0.37% | Test Loss: 0.87483, Test Acc: 0.36%\n",
      "Epoch: 12 | Loss: 1.30142, Acc: 0.38% | Test Loss: 1.08224, Test Acc: 0.36%\n",
      "Epoch: 13 | Loss: 1.30991, Acc: 0.37% | Test Loss: 1.25932, Test Acc: 0.32%\n",
      "Epoch: 14 | Loss: 1.32906, Acc: 0.38% | Test Loss: 1.25106, Test Acc: 0.36%\n",
      "Epoch: 15 | Loss: 1.30961, Acc: 0.38% | Test Loss: 1.09106, Test Acc: 0.35%\n",
      "Epoch: 16 | Loss: 1.32281, Acc: 0.38% | Test Loss: 1.24171, Test Acc: 0.33%\n",
      "Epoch: 17 | Loss: 1.32230, Acc: 0.38% | Test Loss: 1.07389, Test Acc: 0.31%\n",
      "Epoch: 18 | Loss: 1.31240, Acc: 0.38% | Test Loss: 1.29320, Test Acc: 0.36%\n",
      "Epoch: 19 | Loss: 1.31174, Acc: 0.38% | Test Loss: 1.38201, Test Acc: 0.33%\n",
      "Epoch: 20 | Loss: 1.33205, Acc: 0.38% | Test Loss: 1.02916, Test Acc: 0.33%\n",
      "Epoch: 21 | Loss: 1.29786, Acc: 0.39% | Test Loss: 1.10659, Test Acc: 0.33%\n",
      "Epoch: 22 | Loss: 1.30595, Acc: 0.38% | Test Loss: 1.33757, Test Acc: 0.36%\n",
      "early stopping happend!\n",
      "Training complete in 7m 15s\n",
      "Best val Acc: 0.371914\n"
     ]
    }
   ],
   "source": [
    "#Training VGG16 for 100 Epochs\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer_conv = optim.SGD(model_vgg.classifier[6].parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=50, gamma=0.5)\n",
    "\n",
    "model_vgg = model_vgg.to(device)\n",
    "model_vgg_trained,best_loss,best_acc = train_model_manual(model_vgg, criterion, optimizer_conv,exp_lr_scheduler,20,\n",
    "                         num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "iIhG4HBFcvIq"
   },
   "outputs": [],
   "source": [
    "torch.save(model_vgg_trained.state_dict(), '/content/gdrive/MyDrive/gdrivemodel_vgg_trained_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "5fb270b6326e44c8b3abcad0d54a8c24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb52696ddf264cacbc582af0bd4cacf2",
      "max": 102530333,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fdf4610c67d44f0d93bd41939000b3e1",
      "value": 102530333
     }
    },
    "6a879a6321264270bbf729f1bddb7b4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "779e07917c1f44b2a2e03db504a03f30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e257b6ff1e784a06b18ce692528c1d53",
       "IPY_MODEL_5fb270b6326e44c8b3abcad0d54a8c24",
       "IPY_MODEL_7a9448d42f144833bbac274cd03d8e84"
      ],
      "layout": "IPY_MODEL_6a879a6321264270bbf729f1bddb7b4e"
     }
    },
    "7a9448d42f144833bbac274cd03d8e84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbcfc085748943a5bcf204fe39f7e862",
      "placeholder": "​",
      "style": "IPY_MODEL_c8291d0bf13249719bd354e3fb14a971",
      "value": " 97.8M/97.8M [00:01&lt;00:00, 48.6MB/s]"
     }
    },
    "9ff23592487240ab87f8ad45255727ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6e6559ea13843f7ba43c61a4257c347": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb52696ddf264cacbc582af0bd4cacf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbcfc085748943a5bcf204fe39f7e862": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8291d0bf13249719bd354e3fb14a971": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e257b6ff1e784a06b18ce692528c1d53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ff23592487240ab87f8ad45255727ea",
      "placeholder": "​",
      "style": "IPY_MODEL_a6e6559ea13843f7ba43c61a4257c347",
      "value": "100%"
     }
    },
    "fdf4610c67d44f0d93bd41939000b3e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
